{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1646852595314,
     "user": {
      "displayName": "Ayaz Mehmood",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPq5uSsLQW0_Df8q4CdNt7RwLxYL2MTZ86bBoyrg=s64",
      "userId": "11308792519097182174"
     },
     "user_tz": -300
    },
    "id": "LFGBzXuWl2lp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1646853183822,
     "user": {
      "displayName": "Ayaz Mehmood",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPq5uSsLQW0_Df8q4CdNt7RwLxYL2MTZ86bBoyrg=s64",
      "userId": "11308792519097182174"
     },
     "user_tz": -300
    },
    "id": "Wpm2waaamWOG",
    "outputId": "1ab7ba2c-94fb-4e2e-d0f0-5ce09f2f90b0"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('emotion_detection.h5',compile=False) #same file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1646853192700,
     "user": {
      "displayName": "Ayaz Mehmood",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPq5uSsLQW0_Df8q4CdNt7RwLxYL2MTZ86bBoyrg=s64",
      "userId": "11308792519097182174"
     },
     "user_tz": -300
    },
    "id": "M5RpQl3uGVMD",
    "outputId": "6cad5bb6-e27c-45db-eb95-c28961ff7016"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 128)         65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 256)         131328    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 690,439\n",
      "Trainable params: 690,439\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1646853198892,
     "user": {
      "displayName": "Ayaz Mehmood",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPq5uSsLQW0_Df8q4CdNt7RwLxYL2MTZ86bBoyrg=s64",
      "userId": "11308792519097182174"
     },
     "user_tz": -300
    },
    "id": "x2I3KmJWEPLH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 507,
     "status": "ok",
     "timestamp": 1646852862458,
     "user": {
      "displayName": "Ayaz Mehmood",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgPq5uSsLQW0_Df8q4CdNt7RwLxYL2MTZ86bBoyrg=s64",
      "userId": "11308792519097182174"
     },
     "user_tz": -300
    },
    "id": "wHgawbXBFF7b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuauPJmgEVOd"
   },
   "outputs": [],
   "source": [
    "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')  \n",
    "  \n",
    "  \n",
    "cap=cv2.VideoCapture(0)  \n",
    "  \n",
    "while True:  \n",
    "    ret,test_img=cap.read()# captures frame and returns boolean value and captured image  \n",
    "    if not ret:  \n",
    "        continue  \n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)  \n",
    "  \n",
    "  \n",
    "    for (x,y,w,h) in faces_detected:  \n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)  \n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image  \n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))  \n",
    "        img_pixels = image.img_to_array(roi_gray)  \n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)  \n",
    "        img_pixels /= 255  \n",
    "  \n",
    "        predictions = model.predict(img_pixels)  \n",
    "  \n",
    "        #find max indexed array  \n",
    "        max_index = np.argmax(predictions[0])  \n",
    "  \n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')  \n",
    "        predicted_emotion = emotions[max_index]  \n",
    "  \n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)  \n",
    "  \n",
    "    resized_img = cv2.resize(test_img, (1000, 700))  \n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)  \n",
    "  \n",
    "  \n",
    "  \n",
    "    if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed  \n",
    "        break  \n",
    "  \n",
    "cap.release()  \n",
    "cv2.destroyAllWindows  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mC-k2bOZmRJk"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM/bMGSQoKKinINVo3Qoutz",
   "collapsed_sections": [],
   "name": "Image_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
